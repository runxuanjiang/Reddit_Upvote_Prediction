\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Segall2012,Shuaibi2019,Terentiev2014}
\citation{Segall2012,Shuaibi2019}
\citation{Shuaibi2019}
\citation{Segall2012}
\citation{Shuaibi2019}
\citation{Pushshiftio2020}
\newlabel{sec:data}{{3}{2}{Data}{section.3}{}}
\citation{Shuaibi2019}
\citation{Sbert2019}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:uofm_upvotes}{{1}{3}{Distribution of net upvote count for r/uofm.\relax }{figure.caption.1}{}}
\newlabel{sec:methods}{{4}{3}{Methods}{section.4}{}}
\newlabel{fig:uofm_ratio1}{{2}{4}{Distribution of upvote ratio after data cleaning for r/uofm.\relax }{figure.caption.2}{}}
\newlabel{sec:algorithms}{{5}{4}{Algorithms}{section.5}{}}
\newlabel{fig:nnet}{{3}{5}{Feed-forward neural network architecture used in task 1.\relax }{figure.caption.3}{}}
\newlabel{fig:task2_before}{{4}{5}{True (left) and predicted (right) distributions of upvote ratios for r/uofm using model trained on MAE loss.\relax }{figure.caption.4}{}}
\citation{scikit-learn2011}
\newlabel{fig:density}{{5}{6}{Smoothed distribution of upvote ratio (labels) and fitted kernel density for r/uofm.\relax }{figure.caption.5}{}}
\newlabel{fig:task2_after}{{6}{6}{Distribution of predicted upvote ratio after training using weighted MAE.\relax }{figure.caption.6}{}}
\newlabel{fig:ranges}{{7}{6}{Distribution of upvote ratio of posts across three different classification ranges for each subreddit.\relax }{figure.caption.7}{}}
\newlabel{fig:task1res}{{8}{7}{Accuracy and F-1 score of neural network model trained on binary classification of net upvote count (task 1).\relax }{figure.caption.8}{}}
\newlabel{sec:results}{{6}{7}{Results and Discussion}{section.6}{}}
\newlabel{fig:task2res}{{9}{7}{Mean absolute deviation for each subreddit of neural network model trained on task 2, trained using either MAE or WMAE as loss function.\relax }{figure.caption.9}{}}
\newlabel{fig:task3res}{{10}{7}{Results for each model trained on task 3 in r/uofm (RFC refers to random forest classifier, Acc. refers to accuracy).\relax }{figure.caption.10}{}}
\bibstyle{acl_natbib}
\bibdata{emnlp2020}
\newlabel{sec:ethics}{{7}{8}{Ethical Considerations}{section.7}{}}
\bibcite{Pushshiftio2020}{{1}{2020}{{Baumgartner et~al.}}{{Baumgartner, Zannettou, Keegan, Squire, and Blackburn}}}
\bibcite{scikit-learn2011}{{2}{2011}{{Pedregosa et~al.}}{{Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot, and Duchesnay}}}
\bibcite{Sbert2019}{{3}{2019}{{Reimers and Gurevych}}{{}}}
\bibcite{Segall2012}{{4}{2012}{{Segall and Zamoshchin}}{{}}}
\bibcite{Shuaibi2019}{{5}{2019}{{Shuaibi}}{{}}}
\bibcite{Terentiev2014}{{6}{2014}{{Terentiev and Tempest}}{{}}}
\newlabel{fig:task3res2}{{11}{9}{Titles of posts with embeddings that have the highest likelihood of being randomly sampled from the GMM of the range (0.8, 1) and (0, 0.5).\relax }{figure.caption.11}{}}
\newlabel{sec:appdata}{{A.1}{10}{Histograms of net upvote count for each subreddit}{subsection.A.1}{}}
\newlabel{sec:appdistr}{{A.3}{14}{Distribution of predicted upvote ratios using WMAE loss function}{subsection.A.3}{}}
\newlabel{sec:appresult}{{A.4}{19}{Results for the classification of upvote ratio}{subsection.A.4}{}}
